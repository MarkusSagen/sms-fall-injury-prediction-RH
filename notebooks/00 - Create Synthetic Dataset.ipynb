{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d39335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 19:34:17.218243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-30 19:34:17.218257: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c00c8c-2fa8-4576-8c0d-c75410e21c1b",
   "metadata": {},
   "source": [
    "# Generating a Synthetic Dataset\n",
    "This notebook goes over how a synthetic dataset was generated.   \n",
    "The data from Region Halland contains very sensitive patient information and can, therefore, not be included in a notebook. To showcase what has been done and why, we decided to create a synthetic dataset that follows the same general structure and distribution as the original dataset. \n",
    "\n",
    "All values in the dataset are generated radomly to either follow the distribution of the original dataset, as in the case for the dates (`Inpatient_Admissiondatetime`, `Inpatient_Departure`, `omvantDT`), patient gender (`Patient_Gender`), patient age (`Patient_Age`), the number of people having a fall injury (`Class_2016`).   \n",
    "\n",
    "Other values, such as the journal text for each patient (`omvtext_concat`), the medical codes (`sokkod`), patient IDs (`Patient_ID`) are generated to appear similar to the original data and serve the same function. The journal text for each patient, for instance, are free text from the Amazon review dataset with a classification task. We used this dataset because:  \n",
    "1. The dataset is in a free-text form with large and short sentences\n",
    "2. It is a classification task with known labels\n",
    "3. There are more than enough entries in the Amazon review dataset to replace the text needed for 2M patient journal entries. Even though it is not in Swedish and is not about medical text, it should serve a useful dataset for showcasing our methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d7bc6-c3c1-4a0f-b938-0f3bc37204ac",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The original and the synthetic dataset has the following columns:\n",
    "- omv_pk: str\n",
    "- Patient_ID: str\n",
    "- Inpatient_Admissiondatetime: datetime str\n",
    "- Inpatient_Departure: datetime str\n",
    "- omvantDT: str\n",
    "- sokkod: str\n",
    "- omvtext_concat: text\n",
    "- Class_2016: float\n",
    "- Patient_Gender: char\n",
    "- Patient_Age: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d92fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33bb15a5-c631-46e4-adbc-980ebcdc5d9a",
   "metadata": {},
   "source": [
    "# Randomize dates\n",
    "To create randomized hospital admission dates between 2015 and 2020 according to how Swedish medical hospitals note down the time\n",
    "  \n",
    "code from https://stackoverflow.com/questions/553303/generate-a-random-date-between-two-other-dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c40433-11d0-494c-8ba6-c5cc5b75511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def convert_to_strtime(t, time_format='%Y-%m-%d %H:%M'):\n",
    "    return time.strftime(time_format, time.localtime(t))\n",
    "\n",
    "\n",
    "def generate_patient_visits(start, N, time_format='%Y-%m-%d %H:%M'):\n",
    "    \"\"\"Generates N visits after a given start date in assending order (Y-m-d HH:mm)\n",
    "    \n",
    "    :start str:\n",
    "        Start time in YY-mm-dd HH:mm format\n",
    "    :N int: \n",
    "        Number of journal entries to generate for the patient\n",
    "        \n",
    "    returns: [start_time, journal_entry_times, end_time]\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    times_in_hours = []\n",
    "    j_entry = time.mktime(time.strptime(start, time_format))\n",
    "    \n",
    "    for i in range(N):\n",
    "        # how many hours from previous entry\n",
    "        entry_next = random.choices(np.arange(1, 18), k=1)[0] * 3600 \n",
    "        j_entry += entry_next\n",
    "        times.append(convert_to_strtime(j_entry))\n",
    "        times_in_hours.append(j_entry)\n",
    "    \n",
    "    # when the patient leaves the hospital\n",
    "    end = random.choices(np.arange(3, 12), k=1)[0] * 3600 \n",
    "    end += times_in_hours[-1]\n",
    "    end = convert_to_strtime(end)\n",
    "    \n",
    "    end = [end]*N\n",
    "    start = [start]*N\n",
    "    return start, times, end\n",
    "\n",
    "\n",
    "def get_random_start_datetime() -> str:\n",
    "    \"\"\"Generate random year, month, day, hour.\n",
    "    \n",
    "    Returns datetime formated string\n",
    "    \n",
    "    >>> # calculate total time \n",
    "    >>> timedate = get_random_start_datetime()\n",
    "    >>> time.mktime(time.strptime(timedate, '%Y-%m-%d %H:%M'))\n",
    "    \"\"\"\n",
    "    year = random.choices(np.arange(2010, 2018), k=1)[0]\n",
    "    month = random.choices(np.arange(1, 13), k=1)[0]\n",
    "    day = random.choices(np.arange(1, 31), k=1)[0]\n",
    "    hour = random.choices(np.arange(1, 24), k=1)[0]\n",
    "    if month == 2 and day != 28:\n",
    "        day = day % 28 \n",
    "    \n",
    "    return  f\"{year}-{month}-{day} {hour}:00\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffda005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test if works and then replace the below duplicate calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccea891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.arange(50, 300)\n",
    "weights=(population[::-1] % 5)\n",
    "N = random.choices(population, weights=weights, k=1)[0]\n",
    "\n",
    "\"\"\"Most patients have 1-25 journal entries.\"\"\"\n",
    "acc_patients_count = 0\n",
    "limit = 500_000 # how many journals in total to be generated with 1-15 journals\n",
    "    \n",
    "\n",
    "\n",
    "def create_entries_up_to_limit(population, weights=None):\n",
    "    \"\"\"Checks how many journal entries are created. Fills up to a limit of transformed/syntehtic samples.\"\"\"\n",
    "    \n",
    "    global acc_patients_count, limit\n",
    "    global Patient_ID, Patient_journals\n",
    "    global pat_arrived, pat_j_entry, pat_departure\n",
    "\n",
    "    \n",
    "    while acc_patients_count < limit:\n",
    "        N = random.choices(population, weights=weights, k=1)[0]\n",
    "        acc_patients_count += N\n",
    "        num_unique_patients += 1\n",
    "        \n",
    "        Patient_ID.append(num_unique_patients)\n",
    "        Patient_journals.append((num_unique_patients, N))\n",
    "        \n",
    "        start = get_random_start_datetime()\n",
    "        start, journal_entry, end = generate_patient_visits(start, N) \n",
    "        \n",
    "        pat_arrived.append(start)\n",
    "        pat_j_entry.append(journal_entry)\n",
    "        pat_departure.append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd42264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average patient had 50.400788802435 visits\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "times = [\n",
    "    \"Inpatient_Admissiondatetime\": start, \n",
    "    \"Inpatient_Departure\": end,\n",
    "    \"omvantDT\": journal_entry,\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "max_entities = 2_351_348\n",
    "num_falls = 302\n",
    "num_2016 = 190_705\n",
    "\n",
    "num_unique_patients = 0\n",
    "Patient_ID = []\n",
    "Patient_journals = [] # (Patient_ID, Num_entries)\n",
    "\n",
    "pat_arrived = []\n",
    "pat_j_entry = []\n",
    "pat_departure = []\n",
    "\n",
    "\n",
    "\"\"\"Most patients have 1-25 journal entries.\"\"\"\n",
    "acc_patients_count = 0\n",
    "limit = 500_000 # how many journals in total to be generated with 1-15 journals\n",
    "while acc_patients_count < limit:\n",
    "    N = random.choices(np.arange(1, 25), weights=(np.arange(1, 25) % 5), k=1)[0]\n",
    "    acc_patients_count += N\n",
    "    num_unique_patients += 1\n",
    "        \n",
    "    start = get_random_start_datetime()\n",
    "    start, journal_entry, end = generate_patient_visits(start, N) \n",
    "    \n",
    "    pat_arrived.append(start)\n",
    "    pat_j_entry.append(journal_entry)\n",
    "    pat_departure.append(end)\n",
    "    \n",
    "    Patient_ID.append(num_unique_patients)\n",
    "    Patient_journals.append((num_unique_patients, N))\n",
    "    # TODO extract and generate times in loop\n",
    "    \n",
    "\n",
    "\"\"\"...then some have between 20-300 journal entries.\"\"\"\n",
    "limit = 1_500_000 \n",
    "while acc_patients_count < limit:\n",
    "    N = random.choices(np.arange(50, 300), weights=(np.arange(50, 300)[::-1] % 5), k=1)[0]\n",
    "    acc_patients_count += N\n",
    "    num_unique_patients += 1\n",
    "        \n",
    "    start = get_random_start_datetime()\n",
    "    start, journal_entry, end = generate_patient_visits(start, N) \n",
    "    \n",
    "    pat_arrived.append(start)\n",
    "    pat_j_entry.append(journal_entry)\n",
    "    pat_departure.append(end)\n",
    "    \n",
    "    Patient_ID.append(num_unique_patients)\n",
    "    Patient_journals.append((num_unique_patients, N))\n",
    "    # TODO extract and generate times in loop\n",
    "    \n",
    "    \n",
    "\"\"\"...Far fewer have between 300-600 journal entries.\"\"\"\n",
    "limit = max_entities - 600\n",
    "while acc_patients_count < limit:\n",
    "    N = random.choices(np.arange(300, 600), k=1)[0]\n",
    "    acc_patients_count += N\n",
    "    num_unique_patients += 1\n",
    "        \n",
    "    start = get_random_start_datetime()\n",
    "    start, journal_entry, end = generate_patient_visits(start, N) \n",
    "    \n",
    "    pat_arrived.append(start)\n",
    "    pat_j_entry.append(journal_entry)\n",
    "    pat_departure.append(end)\n",
    "    \n",
    "    Patient_ID.append(num_unique_patients)\n",
    "    Patient_journals.append((num_unique_patients, N))\n",
    "    # TODO extract and generate times in loop\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To ensure that we have the same number of total journal entries as the orignal dataset, \n",
    "We create some more patients, which have only one journal entry.\n",
    "\"\"\"\n",
    "limit = max_entities\n",
    "while acc_patients_count < limit:\n",
    "    N = random.choices(np.arange(1, 2), k=1)[0]\n",
    "    acc_patients_count += N\n",
    "    num_unique_patients += 1\n",
    "        \n",
    "    start = get_random_start_datetime()\n",
    "    start, journal_entry, end = generate_patient_visits(start, N) \n",
    "    \n",
    "    pat_arrived.append(start)\n",
    "    pat_j_entry.append(journal_entry)\n",
    "    pat_departure.append(end)\n",
    "    \n",
    "    Patient_ID.append(num_unique_patients)\n",
    "    Patient_journals.append((num_unique_patients, N))\n",
    "    # TODO extract and generate times in loop\n",
    "    \n",
    "\n",
    "Inpatient_Admissiondatetime = pat_arrived\n",
    "omvantDT = pat_j_entry\n",
    "Inpatient_Departure = pat_departure\n",
    "\n",
    "\n",
    "# On average how many entries/notes does each patient have during their stay\n",
    "total_visits = 0\n",
    "for k, v in Patient_journals:\n",
    "    total_visits += v\n",
    "    \n",
    "avg_num_journal_entries = total_visits/len(Patient_journals)\n",
    "print(f\"The average patient had {avg_num_journal_entries} visits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e53de-2578-45c1-ab7a-d80b98ae1e74",
   "metadata": {},
   "source": [
    "## Add free-text journal notes\n",
    "Based on the Amazon Review dataset  \n",
    "Reviews are in fre-text form in English  \n",
    "\n",
    "- Positive reviews (4+ stars) are the most plentiful, and therefor assigned to all patients\n",
    "- Negative reviews (1 stars) occur more seldom, and is assigned to patients that have had a fall injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b9ce5a-d477-4cd1-8f33-0d6993cb7bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/markussagen/.cache/huggingface/datasets/amazon_us_reviews/Books_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2198c266d5a04a86ab5aa9b452b394b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 4s, sys: 1.99 s, total: 17min 6s\n",
      "Wall time: 17min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Politics of Character Design. Most people will have heard about all the psychological ideas in this book, whether or not you believe some of it depends on your experience and level of intelligence. I didn\\'t read the whole thing, it\\'s not that interesting, but I skimmed through more than half of it. The majority of the book is really about how for many people their inherited politics will distort their interpretation of characters, you shouldn\\'t need a book to figure this out and if you know the principle then the specifics are easy to figure out on a case by case basis. Various conclusions can be inferred from this predicate, which don\\'t need to be written about here, but in short my advice is don\\'t be a politician. The only thing useful is that there is a pretty clear admission by the Japanese regional guys that they think African types, Polynesians, and very Asian looking people are ugly, it\\'s very difficult to find this type of statement from these types of crypto-white supremacists since they will usually try to evade the issue by referring to \\\\\\\\\"demographics\\\\\\\\\". Demographics are meaningless in fantasy settings, the only questions that matter are how desirable is the fantasy to the audience and why but the answers to these questions can be obscured by clever political word strategy.  For any beginners: all you have to know is that game characters are actors(I\\'m using this word in a very general way) defined by what they do - they do things to reach some desired goal, and that they are representations of some quality or idea. Their popularity depends on the appeal of their actions and the appeal of what they represent.',\n",
       " 'This bible is a Christian bible by a deceptive pastor trying to pass himself off as a Rabbi. The Jewish bible does NOT have the &#34;new testament&#34; attached to it. Also the commentaries written by pastor Koniuchowsky are misunderstandings such as what he writes about Isaiah 53 and why Jews do not read it in the synagogue (there are plenty of resources explaining why not so I wont put it on this review) If you want to learn about Judaism and the Jewish bible please check out Artscroll or JPS.',\n",
       " 'All my packages were stolen including the book.  Unable to rate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d = load_dataset('amazon_us_reviews', 'Books_v1_00')\n",
    "\n",
    "# Score 5 - simulates NOT having a fall injury\n",
    "# Score 1 - simulates having a fall injury\n",
    "score = {\n",
    "    1: [], \n",
    "    2: [],\n",
    "    3: [],\n",
    "    4: [],\n",
    "    5: [],\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for review in d['train']:\n",
    "    if len(score[5]) < max_entities:\n",
    "        r = review['star_rating']\n",
    "        if r == 1 or r == 5 or r == 4:\n",
    "            if r == 4:\n",
    "                r = 5\n",
    "            \n",
    "            text = review['review_body']\n",
    "            num_words = len(text.split(\" \"))\n",
    "            if num_words >= 5:\n",
    "                score[r].append(review['review_body'])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "np.random.shuffle(score[5])\n",
    "np.random.shuffle(score[1])\n",
    "\n",
    "score[1][:3]\n",
    "#pp.pprint(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb17e56-c373-40f0-9793-d340831bb65d",
   "metadata": {},
   "source": [
    "# sokkod \n",
    "Generate random sokkods from English dictionary\n",
    "https://stackoverflow.com/a/18835426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6984dcd5-4ca3-4b00-9845-0b37fbfb9155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "\n",
    "max_entities = 2_351_348\n",
    "num_falls = 302\n",
    "num_2016 = 190_705\n",
    "\n",
    "word_site = \"https://www.mit.edu/~ecprice/wordlist.10000\"\n",
    "response = requests.get(word_site)\n",
    "WORDS = response.content.splitlines()\n",
    "\n",
    "words = []\n",
    "for w in WORDS:\n",
    "    if len(w)> 4:\n",
    "        words.append(w)\n",
    "\n",
    "\n",
    "sokkod = []\n",
    "omv_pk = []\n",
    "s = random.choices(words, k=100)\n",
    "\n",
    "for pat_id, entries in Patient_journals:\n",
    "    r = random.choices(np.arange(77, 3319))[0] # random numbers only\n",
    "    for _ in range(entries):\n",
    "        sokord = random.choices(s, k=1)[0].decode(\"utf-8\")\n",
    "        omv_text = f'{pat_id*r % 91781}_{sokord}'\n",
    "        \n",
    "        sokkod.append(sokord)\n",
    "        omv_pk.append(omv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8798fb-c010-4e6f-831a-040391b50348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markussagen/.pyenv/versions/medbert/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Generate ages from a predefined dist\n",
    "age = pd.read_csv('../data/age_dist.csv', index_col=0)\n",
    "age = list(age['0'])\n",
    "Patient_Age = []\n",
    "for i in range(len(age)):\n",
    "    Patient_Age.append(float(age[i])) # since the age from database was floats\n",
    "\n",
    "Patient_Age = np.array(Patient_Age)\n",
    "np.random.shuffle(Patient_Age)\n",
    "Patient_Age = Patient_Age[:len(Patient_ID)]\n",
    "Patient_Age = list(Patient_Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89798700-7abd-4441-8e00-82e9465c5d95",
   "metadata": {},
   "source": [
    "#### Assign which patient has fallen\n",
    "The risk for a patient to have a fall injury is related to their age and gender. \n",
    "Since it is known how many patients have had a fall injury during 2016, those numbers are also assigned here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d23e5ce0-a120-4364-8612-3954ab2785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "omvtext_concat = []\n",
    "Class_2016 = []\n",
    "Patient_IDs_from_2016 = []\n",
    "\n",
    "def is_from_2016(lst):\n",
    "    return [True if len(lst[0].split(\"2016\"))>1 else False][0]\n",
    "\n",
    "# Set all default to have no fall injury\n",
    "for pat_id, num_entries in Patient_journals:\n",
    "    texts   = []\n",
    "    labels  = []\n",
    "    is_2016 = is_from_2016(pat_arrived[pat_id-1])\n",
    "    for i in range(num_entries):\n",
    "        texts.append(score[5][idx])\n",
    "        if is_2016:\n",
    "            labels.append(float(0))\n",
    "            Patient_IDs_from_2016.append(pat_id)\n",
    "        else:\n",
    "            labels.append(np.nan)\n",
    "        idx += 1\n",
    "    \n",
    "    omvtext_concat.append(texts)\n",
    "    Class_2016.append(labels)\n",
    "\n",
    "\n",
    "ids_with_falls = random.choices(Patient_IDs_from_2016, k=302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb7814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "082af518-8565-4ccc-aaa0-ceaf4c8e75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose to replace one of the entries with a fall injury\n",
    "# Label those examples\n",
    "for i, idx in enumerate(ids_with_falls):\n",
    "    entries = omvtext_concat[idx]\n",
    "    idx_replace = random.choices(np.arange(len(entries)), k=1)[0]\n",
    "    omvtext_concat[idx][idx_replace] = score[1][i]\n",
    "    Class_2016[idx][idx_replace] = float(1)\n",
    "    \n",
    "# Also create some patients with fall injuries but not labeled\n",
    "ids_unlabeled_with_fall = random.choices(np.arange(len(Patient_ID)), k=5500)\n",
    "for i, idx in enumerate(ids_unlabeled_with_fall):\n",
    "    entries = omvtext_concat[idx]\n",
    "    idx_replace = random.choices(np.arange(len(entries)), k=1)[0]\n",
    "    omvtext_concat[idx][idx_replace] = score[1][i]\n",
    "\n",
    "# Also select some random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2f538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a7d248c-b3e9-4941-8908-a200a589bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Patient Gender. Males are more likely to fall\n",
    "Patient_Gender = random.choices((\"M\", \"F\"), weights=(48, 52), k=len(Patient_ID))\n",
    "Patient_Gender = np.array(Patient_Gender)\n",
    "Patient_Gender[ids_with_falls] = random.choices((\"M\", \"F\"), weights=(69, 31), k=302)\n",
    "Patient_Gender = list(Patient_Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f54a3-77a9-41fd-aa21-8903d7fc5b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bringing it all toghether\n",
    "We take all categories of the patient and, if the data is in a list of list, it is flattened. All categories are assembled to a Pandas DataFrame and saved as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e771ddf-5de6-4f2a-bf6d-d89a49cec3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    return list(itertools.chain(*list_of_lists))\n",
    "\n",
    "def extend(lst):\n",
    "    global Patient_journals\n",
    "    extended_list = []\n",
    "    for pat_id, entries in Patient_journals:\n",
    "        idx = pat_id-1\n",
    "        values = [lst[idx]]*entries # replicate for all entries\n",
    "        extended_list.append(values)\n",
    "    return extended_list\n",
    "            \n",
    "_omv_pk = omv_pk\n",
    "_sokkod = sokkod\n",
    "\n",
    "_Inpatient_Admissiondatetime = flatten(Inpatient_Admissiondatetime)\n",
    "_Inpatient_Departure = flatten(Inpatient_Departure)\n",
    "_omvantDT = flatten(omvantDT)\n",
    "_omvtext_concat = flatten(omvtext_concat)\n",
    "_Class_2016 = flatten(Class_2016)\n",
    "\n",
    "_Patient_Age = extend(Patient_Age)\n",
    "_Patient_Age = flatten(_Patient_Age)\n",
    "_Patient_Gender = extend(Patient_Gender)\n",
    "_Patient_Gender = flatten(_Patient_Gender)\n",
    "_Patient_ID = extend(Patient_ID)\n",
    "_Patient_ID = flatten(_Patient_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "972d7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the label on some of the patients for the 2016 dataset\n",
    "# Since the real dataset had some data points from 2016 with unknown label\n",
    "\n",
    "num_unlabeled    = 0\n",
    "known_fall_injuries = [v for v in _Class_2016 if v == 0]\n",
    "total_labeled_examples = 172_250\n",
    "total_to_relabel = len(known_fall_injuries) - total_labeled_examples\n",
    "\n",
    "for i, _ in enumerate(_Class_2016):\n",
    "    if _Class_2016[i] == 0:\n",
    "        if random.random() > 0.4 and num_unlabeled < total_to_relabel:\n",
    "            _Class_2016[i] = np.nan\n",
    "            num_unlabeled += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3e5ad-58ae-4485-bef2-fb0741d5594d",
   "metadata": {},
   "source": [
    "### Update format for all notes related to times\n",
    "Noticed that the hours start with a leading 0 if the hour of the day is before 10AM     \n",
    "And since generating the dataset took quite some time, the dataset is modified to be in the correct format afterwards instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde1a443-1a82-4c38-a732-c58e9cd2d4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def convert strings to correct format\n",
    "def convert_datetime_str_format(datetime_str_list):\n",
    "    \"\"\"Converts list of Datetime Strings to expected format.\n",
    "    \n",
    "    >>> convert_datetime_str_format(['YYYY-MM-DD H:MM'])\n",
    "    >>> returns ['YYYY-MM-DD HH:MM:SS:000']\n",
    "    \"\"\"\n",
    "    converted_datetimes_list = []\n",
    "    for time_str in datetime_str_list:\n",
    "        year_month_day, hour_minutes = time_str.split(\" \")\n",
    "        hour, minutes = hour_minutes.split(\":\")\n",
    "\n",
    "        # If has no leading 0 or before 10AM\n",
    "        if len(hour) != 2:\n",
    "            hour = '0'+hour\n",
    "\n",
    "        converted_datetimes_list.append(year_month_day + \" \" + hour + \":00:00.000\")\n",
    "    return converted_datetimes_list\n",
    "\n",
    "\n",
    "# Convert the entries with datetime strings\n",
    "_Inpatient_Admissiondatetime = convert_datetime_str_format(_Inpatient_Admissiondatetime)\n",
    "_Inpatient_Departure         = convert_datetime_str_format(_Inpatient_Departure)\n",
    "_omvantDT                    = convert_datetime_str_format(_omvantDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4b19f",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "425972d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "d = {\n",
    "    \"omv_pk\": _omv_pk,\n",
    "    \"Patient_ID\": _Patient_ID,\n",
    "    \"Inpatient_Admissiondatetime\": _Inpatient_Admissiondatetime,\n",
    "    \"Inpatient_Departure\": _Inpatient_Departure,\n",
    "    \"omvantDT\": _omvantDT,\n",
    "    \"sokkod\": _sokkod,\n",
    "    \"omvtext_concat\": _omvtext_concat,\n",
    "    \"Class_2016\": _Class_2016,\n",
    "    \"Patient_Gender\": _Patient_Gender,\n",
    "    \"Patient_Age\": _Patient_Age,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv(\"../data/synthethetic_data_medical.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5126abe-023f-4993-bda1-a363a28c011b",
   "metadata": {},
   "source": [
    "## Load the saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caabc839-ebb3-40fa-99b0-8161c2e09198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>omv_pk</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Inpatient_Admissiondatetime</th>\n",
       "      <th>Inpatient_Departure</th>\n",
       "      <th>omvantDT</th>\n",
       "      <th>sokkod</th>\n",
       "      <th>omvtext_concat</th>\n",
       "      <th>Class_2016</th>\n",
       "      <th>Patient_Gender</th>\n",
       "      <th>Patient_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082_establishment</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-5-4 6:00</td>\n",
       "      <td>2010-05-05 23:00</td>\n",
       "      <td>2010-05-04 16:00</td>\n",
       "      <td>establishment</td>\n",
       "      <td>This is a wonderful,  wonderful  book.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082_specified</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-5-4 6:00</td>\n",
       "      <td>2010-05-05 23:00</td>\n",
       "      <td>2010-05-04 19:00</td>\n",
       "      <td>specified</td>\n",
       "      <td>I enjoyed the book.&lt;br /&gt;&lt;br /&gt;Thanks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082_living</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-5-4 6:00</td>\n",
       "      <td>2010-05-05 23:00</td>\n",
       "      <td>2010-05-04 23:00</td>\n",
       "      <td>living</td>\n",
       "      <td>A wonderful time capsule to Havana's glory days.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082_bookmarks</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-5-4 6:00</td>\n",
       "      <td>2010-05-05 23:00</td>\n",
       "      <td>2010-05-05 12:00</td>\n",
       "      <td>bookmarks</td>\n",
       "      <td>The book is by a Rabbi, but is for people who ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4398_helicopter</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-8-17 10:00</td>\n",
       "      <td>2011-08-19 15:00</td>\n",
       "      <td>2011-08-18 00:00</td>\n",
       "      <td>helicopter</td>\n",
       "      <td>Very important and powerfully documented book ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               omv_pk  Patient_ID Inpatient_Admissiondatetime  \\\n",
       "0  1082_establishment           1               2010-5-4 6:00   \n",
       "1      1082_specified           1               2010-5-4 6:00   \n",
       "2         1082_living           1               2010-5-4 6:00   \n",
       "3      1082_bookmarks           1               2010-5-4 6:00   \n",
       "4     4398_helicopter           2             2011-8-17 10:00   \n",
       "\n",
       "  Inpatient_Departure          omvantDT         sokkod  \\\n",
       "0    2010-05-05 23:00  2010-05-04 16:00  establishment   \n",
       "1    2010-05-05 23:00  2010-05-04 19:00      specified   \n",
       "2    2010-05-05 23:00  2010-05-04 23:00         living   \n",
       "3    2010-05-05 23:00  2010-05-05 12:00      bookmarks   \n",
       "4    2011-08-19 15:00  2011-08-18 00:00     helicopter   \n",
       "\n",
       "                                      omvtext_concat  Class_2016  \\\n",
       "0             This is a wonderful,  wonderful  book.         NaN   \n",
       "1              I enjoyed the book.<br /><br />Thanks         NaN   \n",
       "2   A wonderful time capsule to Havana's glory days.         NaN   \n",
       "3  The book is by a Rabbi, but is for people who ...         NaN   \n",
       "4  Very important and powerfully documented book ...         NaN   \n",
       "\n",
       "  Patient_Gender  Patient_Age  \n",
       "0              M         88.0  \n",
       "1              M         88.0  \n",
       "2              M         88.0  \n",
       "3              M         88.0  \n",
       "4              F         78.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/synthethetic_data_medical.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b147be-fa39-4ecf-bede-7ef6f2399362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medbert",
   "language": "python",
   "name": "medbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
